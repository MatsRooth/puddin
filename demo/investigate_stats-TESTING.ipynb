{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to investigate getting stats for puddin files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "#> imports\n",
    "import pandas as pd\n",
    "import pyconll\n",
    "import sys\n",
    "\n",
    "from collections import namedtuple\n",
    "from itertools import islice\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "#> constants\n",
    "DATA_GRP = 'val'\n",
    "DATA_DIR = Path('data/puddin')\n",
    "CAP = 2000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select dataset and load info dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conll_id</th>\n",
       "      <th>data_group</th>\n",
       "      <th>conllu_stem</th>\n",
       "      <th>docs_in_conllu</th>\n",
       "      <th>excl_type</th>\n",
       "      <th>known_fail</th>\n",
       "      <th>success</th>\n",
       "      <th>slice</th>\n",
       "      <th>text_altered</th>\n",
       "      <th>missing</th>\n",
       "      <th>slice_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pcc_val_12931</th>\n",
       "      <td>pcc_eng_val_1.7954_x12931</td>\n",
       "      <td>val</td>\n",
       "      <td>pcc_eng_val-01</td>\n",
       "      <td>9999</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>pcc_eng_val_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcc_val_15927</th>\n",
       "      <td>pcc_eng_val_1.9820_x15927</td>\n",
       "      <td>val</td>\n",
       "      <td>pcc_eng_val-01</td>\n",
       "      <td>9999</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>pcc_eng_val_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcc_val_16966</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>val</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>a0wrd</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                conll_id data_group     conllu_stem  \\\n",
       "raw_id                                                                \n",
       "pcc_val_12931  pcc_eng_val_1.7954_x12931        val  pcc_eng_val-01   \n",
       "pcc_val_15927  pcc_eng_val_1.9820_x15927        val  pcc_eng_val-01   \n",
       "pcc_val_16966                       <NA>        val            <NA>   \n",
       "\n",
       "               docs_in_conllu excl_type  known_fail  success          slice  \\\n",
       "raw_id                                                                        \n",
       "pcc_val_12931            9999      <NA>       False     True  pcc_eng_val_1   \n",
       "pcc_val_15927            9999      <NA>       False     True  pcc_eng_val_1   \n",
       "pcc_val_16966               0     a0wrd       False    False           <NA>   \n",
       "\n",
       "               text_altered  missing slice_code  \n",
       "raw_id                                           \n",
       "pcc_val_12931          <NA>    False          1  \n",
       "pcc_val_15927          <NA>    False          1  \n",
       "pcc_val_16966          True    False        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_code = f'Pcc{DATA_GRP[:2].capitalize()}'\n",
    "group_dir = DATA_DIR.joinpath(f'{data_code}.conll')\n",
    "\n",
    "info_path = DATA_DIR.joinpath('info/validation_by_group/status-overview/')\n",
    "\n",
    "for group_info_file in info_path.glob('*status-info*pkl*'):\n",
    "    # for testing\n",
    "    if not group_info_file.stem.startswith(data_code):\n",
    "        continue\n",
    "    else:\n",
    "        group_info = pd.read_pickle(group_info_file)\n",
    "        break\n",
    "group_info.sample(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get conllu path from info dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conllu: data/puddin/PccVa.conll/pcc_eng_val-01.conllu\n",
      "Counting data in data/puddin/PccVa.conll/pcc_eng_val-01.conllu...\n"
     ]
    }
   ],
   "source": [
    "if not group_dir.is_dir():\n",
    "    sys.exist('ERROR: cannot find conllu dir for', data_code, '\\n>> Program Terminated.')\n",
    "else:\n",
    "    stem_col = group_info.conllu_stem\n",
    "    for stem in stem_col.unique():\n",
    "        conllu_path = group_dir.joinpath(f'{stem}.conllu')\n",
    "        if conllu_path.is_file():# and conllu_path.stat().st_size > 0:\n",
    "            print(f'conllu: {conllu_path}')\n",
    "            #TODO: temp for debugging! REMOVE\n",
    "            break\n",
    "        else:\n",
    "            print(f'{conllu_path} does not exist, or is not a file.')\n",
    "    #! this should go within loop, but only doing one for devel so pulling it out\n",
    "    print(f'Counting data in {conllu_path}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over conllu file and collect word & character counts for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN DEVELOPMENT: only reading first 2000 sentences\n",
      "count                          2000\n",
      "unique                           91\n",
      "top       pcc_eng_val_1.0016_x00024\n",
      "freq                            133\n",
      "Name: Did, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wrd_count</th>\n",
       "      <th>chr_count</th>\n",
       "      <th>wlen_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.30</td>\n",
       "      <td>82.00</td>\n",
       "      <td>4.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.25</td>\n",
       "      <td>59.76</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.00</td>\n",
       "      <td>37.00</td>\n",
       "      <td>4.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.00</td>\n",
       "      <td>114.00</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>76.00</td>\n",
       "      <td>392.00</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wrd_count  chr_count  wlen_mean\n",
       "count    2000.00    2000.00    2000.00\n",
       "mean       17.30      82.00       4.79\n",
       "std        12.25      59.76       0.98\n",
       "min         1.00       1.00       1.00\n",
       "25%         8.00      37.00       4.19\n",
       "50%        15.00      70.00       4.70\n",
       "75%        24.00     114.00       5.30\n",
       "max        76.00     392.00      12.00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_sentence(sentence):\n",
    "    sent_tuple = namedtuple(\n",
    "        'sent_counts',\n",
    "        ['Sid', 'Did', 'txt',\n",
    "         'lemmas', 'words', \n",
    "         #? is `wlens` (word lengths) truly needed? \n",
    "         #  ^(mean wlen can be calculated by `chr_count/wrd_count` at any level)\n",
    "         'wlens',\n",
    "         'wrd_count', 'chr_count',\n",
    "         'wlen_mean'])\n",
    "    #* NOTE: this excludes all punctuation symbols!\n",
    "    tok_objects = tuple(\n",
    "        tok for tok in sentence._tokens if tok.deprel != 'punct')\n",
    "    # lemmas = pd.Series(tok.lemma for tok in tok_objects)\n",
    "    words = pd.Series(tok.form for tok in tok_objects)\n",
    "    word_lengths = pd.Series(len(word) for word in words)\n",
    "    word_count = len(words)\n",
    "    char_count = sum(word_lengths)\n",
    "    doc_id = sentence.id.rsplit('_',1)[0]\n",
    "    yield sent_tuple(sentence.id, doc_id, sentence.text,\n",
    "                    pd.Series(tok.lemma for tok in tok_objects), \n",
    "                    words, word_lengths,\n",
    "                    word_count, char_count,\n",
    "                    char_count/word_count)\n",
    "\n",
    "def gen_sentence_info(conllu_path, sentence_cap: int=None):\n",
    "\n",
    "    # doc_id = None\n",
    "    file_iter = pyconll.iter_from_file(conllu_path)\n",
    "    if sentence_cap:\n",
    "        print(f'IN DEVELOPMENT: only reading first {sentence_cap} sentences')\n",
    "        file_iter = islice(file_iter, sentence_cap)\n",
    "        \n",
    "    for sentence in file_iter:\n",
    "        # if sentence.meta_present('newdoc id'):# and sentence.meta_value('newdoc_id') != doc_id:\n",
    "        #     doc_id = sentence.meta_value('newdoc id')\n",
    "        #     print(doc_id)\n",
    "        # elif not doc_id:\n",
    "        #     print(f'! WARNING: doc {doc_id} info not found!')\n",
    "        # elif not sentence.id.startswith(doc_id):\n",
    "        #     print(f'~!~ WARNING: doc {doc_id} and sentence ids do not match!')\n",
    "        # # print(sentence.text)\n",
    "        yield from read_sentence(sentence)\n",
    "        \n",
    "conll_iter = gen_sentence_info(conllu_path, sentence_cap=CAP)\n",
    "sdf = pd.DataFrame(conll_iter)\n",
    "sdf = sdf.set_index('Sid')\n",
    "sdf.sample(3).sort_index()  \n",
    "print(sdf.Did.describe())\n",
    "sdf.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by document and add stats at document level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_counts(df, prefix: str='s'):\n",
    "    \n",
    "    doc_dict = {}\n",
    "    counts = df.loc[:, df.columns.str.endswith('count')]\n",
    "    #> pull out only the distinguishing str\n",
    "    counts.columns = counts.columns.str.replace('count','').str.strip('_')\n",
    "    \n",
    "    # first descriptor is \"count\" ~ do not need, so drop it here\n",
    "    counts_desc = counts.describe().iloc[1:, :]\n",
    "    # add median and sum rows, but \"assign\" as columns\n",
    "    t_counts_desc = counts_desc.transpose().assign(\n",
    "        #! turns out median is identical with `50%` value already in `counts_desc`\n",
    "        #   and `wrd_total` is redundant with lmm_count but leaving that\n",
    "        # median=counts.median(),\n",
    "        total=counts.sum())\n",
    "\n",
    "    # for each row of combined descriptive stats automated df:\n",
    "    #   1. pull out row as its *own* dataframe\n",
    "    #   2. rename cols to indicate row/data (i.e. 'wrd_' or 'chr_')\n",
    "    for row_ix in t_counts_desc.index:\n",
    "        row_df = t_counts_desc.loc[[row_ix], :]\n",
    "        #// print('generalized `describe` metrics:',row_df.columns.to_list(),sep='\\n')\n",
    "        row_df.columns = prefix+row_ix+'_'+row_df.columns\n",
    "        #// print('--become-->')\n",
    "        #// print('individualized `describe` metrics:', row_df.columns.to_list(), sep='\\n')\n",
    "        row = row_df.iloc[0, :]\n",
    "        row_dict = row.to_dict()\n",
    "        doc_dict.update(row_dict)\n",
    "    # pprint(doc_dict)\n",
    "    return doc_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Loop through by-sentence dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D_Swrd_mean</th>\n",
       "      <th>D_Swrd_std</th>\n",
       "      <th>D_Swrd_min</th>\n",
       "      <th>D_Swrd_25%</th>\n",
       "      <th>D_Swrd_median</th>\n",
       "      <th>D_Swrd_75%</th>\n",
       "      <th>D_Swrd_max</th>\n",
       "      <th>D_Swrd_total</th>\n",
       "      <th>D_Schr_mean</th>\n",
       "      <th>D_Schr_std</th>\n",
       "      <th>...</th>\n",
       "      <th>D_lmm_unique</th>\n",
       "      <th>D_lmm_top</th>\n",
       "      <th>D_lmm_topfreq</th>\n",
       "      <th>D_wlen_mean</th>\n",
       "      <th>D_wlen_std</th>\n",
       "      <th>D_wlen_min</th>\n",
       "      <th>D_wlen_25%</th>\n",
       "      <th>D_wlen_median</th>\n",
       "      <th>D_wlen_75%</th>\n",
       "      <th>D_wlen_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pcc_eng_val_1.0001_x00001</th>\n",
       "      <td>7.75</td>\n",
       "      <td>6.670832</td>\n",
       "      <td>2</td>\n",
       "      <td>3.75</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23</td>\n",
       "      <td>62</td>\n",
       "      <td>34.625</td>\n",
       "      <td>24.142065</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "      <td>4.467742</td>\n",
       "      <td>2.244978</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcc_eng_val_1.0002_x00002</th>\n",
       "      <td>13.444444</td>\n",
       "      <td>8.719391</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>29</td>\n",
       "      <td>121</td>\n",
       "      <td>62.888889</td>\n",
       "      <td>42.609988</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>a</td>\n",
       "      <td>8</td>\n",
       "      <td>4.677686</td>\n",
       "      <td>2.523935</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcc_eng_val_1.0003_x00005</th>\n",
       "      <td>13.92</td>\n",
       "      <td>7.915807</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35</td>\n",
       "      <td>348</td>\n",
       "      <td>62.24</td>\n",
       "      <td>32.156233</td>\n",
       "      <td>...</td>\n",
       "      <td>153</td>\n",
       "      <td>you</td>\n",
       "      <td>19</td>\n",
       "      <td>4.471264</td>\n",
       "      <td>2.284336</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcc_eng_val_1.0004_x00006</th>\n",
       "      <td>21.076923</td>\n",
       "      <td>14.068186</td>\n",
       "      <td>5</td>\n",
       "      <td>10.25</td>\n",
       "      <td>20.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>72</td>\n",
       "      <td>548</td>\n",
       "      <td>89.846154</td>\n",
       "      <td>58.064579</td>\n",
       "      <td>...</td>\n",
       "      <td>227</td>\n",
       "      <td>the</td>\n",
       "      <td>40</td>\n",
       "      <td>4.262774</td>\n",
       "      <td>2.323145</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcc_eng_val_1.0005_x00007</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9.433981</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>50.2</td>\n",
       "      <td>48.215143</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>the</td>\n",
       "      <td>6</td>\n",
       "      <td>5.02</td>\n",
       "      <td>2.90313</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           D_Swrd_mean  D_Swrd_std  D_Swrd_min  D_Swrd_25%  \\\n",
       "D_id                                                                         \n",
       "pcc_eng_val_1.0001_x00001         7.75    6.670832           2        3.75   \n",
       "pcc_eng_val_1.0002_x00002    13.444444    8.719391           2         8.0   \n",
       "pcc_eng_val_1.0003_x00005        13.92    7.915807           1         8.0   \n",
       "pcc_eng_val_1.0004_x00006    21.076923   14.068186           5       10.25   \n",
       "pcc_eng_val_1.0005_x00007         10.0    9.433981           1         1.0   \n",
       "\n",
       "                           D_Swrd_median  D_Swrd_75%  D_Swrd_max  \\\n",
       "D_id                                                               \n",
       "pcc_eng_val_1.0001_x00001            6.0         9.0          23   \n",
       "pcc_eng_val_1.0002_x00002           12.0        20.0          29   \n",
       "pcc_eng_val_1.0003_x00005           14.0        18.0          35   \n",
       "pcc_eng_val_1.0004_x00006           20.5        26.5          72   \n",
       "pcc_eng_val_1.0005_x00007            9.0        17.0          22   \n",
       "\n",
       "                           D_Swrd_total  D_Schr_mean  D_Schr_std  ...  \\\n",
       "D_id                                                              ...   \n",
       "pcc_eng_val_1.0001_x00001            62       34.625   24.142065  ...   \n",
       "pcc_eng_val_1.0002_x00002           121    62.888889   42.609988  ...   \n",
       "pcc_eng_val_1.0003_x00005           348        62.24   32.156233  ...   \n",
       "pcc_eng_val_1.0004_x00006           548    89.846154   58.064579  ...   \n",
       "pcc_eng_val_1.0005_x00007            50         50.2   48.215143  ...   \n",
       "\n",
       "                           D_lmm_unique  D_lmm_top  D_lmm_topfreq  \\\n",
       "D_id                                                                \n",
       "pcc_eng_val_1.0001_x00001            53          a              3   \n",
       "pcc_eng_val_1.0002_x00002            78          a              8   \n",
       "pcc_eng_val_1.0003_x00005           153        you             19   \n",
       "pcc_eng_val_1.0004_x00006           227        the             40   \n",
       "pcc_eng_val_1.0005_x00007            35        the              6   \n",
       "\n",
       "                           D_wlen_mean  D_wlen_std  D_wlen_min  D_wlen_25%  \\\n",
       "D_id                                                                         \n",
       "pcc_eng_val_1.0001_x00001     4.467742    2.244978           1         3.0   \n",
       "pcc_eng_val_1.0002_x00002     4.677686    2.523935           1         3.0   \n",
       "pcc_eng_val_1.0003_x00005     4.471264    2.284336           1         3.0   \n",
       "pcc_eng_val_1.0004_x00006     4.262774    2.323145           1         2.0   \n",
       "pcc_eng_val_1.0005_x00007         5.02     2.90313           1         3.0   \n",
       "\n",
       "                          D_wlen_median D_wlen_75% D_wlen_max  \n",
       "D_id                                                           \n",
       "pcc_eng_val_1.0001_x00001           4.0        6.0          9  \n",
       "pcc_eng_val_1.0002_x00002           4.0        7.0         11  \n",
       "pcc_eng_val_1.0003_x00005           4.0        6.0         13  \n",
       "pcc_eng_val_1.0004_x00006           4.0        6.0         12  \n",
       "pcc_eng_val_1.0005_x00007           4.5        7.0         12  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def describe_word_level_series(wrd_lvl_ser: pd.Series, metric_prefix: str):\n",
    "    \n",
    "    if not metric_prefix.endswith('_'): \n",
    "        metric_prefix += '_'\n",
    "    ser_desc = wrd_lvl_ser.describe()\n",
    "    ser_desc = ser_desc.loc[ser_desc.index != 'count']\n",
    "    ser_desc.index = metric_prefix + ser_desc.index\n",
    "    doc_dict.update(ser_desc.to_dict())\n",
    "    \n",
    "    return doc_dict\n",
    "\n",
    "d_dicts = []\n",
    "prefix = 'S'\n",
    "# TODO: make this a method/function\n",
    "for doc, gdf in sdf.groupby('Did'):\n",
    "    # print(doc)\n",
    "    doc_dict = describe_counts(gdf,prefix)\n",
    "    doc_dict = {f'D_{k}':v for k,v in doc_dict.items()}\n",
    "\n",
    "    #TODO: 👉 use `s_wlen_list` col to calculate mean doc wlen (or not??)\n",
    "    \n",
    "    doc_lemmas = pd.Series(lm for lm_list in gdf.lemmas for lm in lm_list)\n",
    "    doc_wlens = pd.Series(wl for wl_list in gdf.wlens for wl in wl_list)\n",
    "    doc_add = {\n",
    "\n",
    "        # document id\n",
    "        'D_id': doc,  \n",
    "              \n",
    "        # total sentences in doc (~ sentences/per doc)\n",
    "        # (synonymous with the `count` descriptors dropped above)\n",
    "        'D_snt_count': len(gdf),\n",
    "        \n",
    "        'D_lemmas': doc_lemmas, \n",
    "        'D_lemmas_concat': ' '.join(doc_lemmas),\n",
    "        \n",
    "        # REPLACE ALL OF THIS MANUAL ENTRY WITH `describe()`\n",
    "        # 'D_wlens': doc_wlens,\n",
    "        # # total char in doc / total words in doc\n",
    "        # # 'D_wlen_mean.0': doc_dict[f'D_{prefix}chr_total']/doc_dict[f'D_{prefix}wrd_total'],\n",
    "        # # NOTE: this 👆 could also be done by getting the mean of all \n",
    "        # #   the wlen elements for each value/cell of `s_wlen_list` col, \n",
    "        # #   but that is unnecessary -> returns identical result:\n",
    "        # # ^ But, if creating series of all word lengths _anyway_, this is cleaner:\n",
    "        # 'D_wlen_mean': doc_wlens.mean(),\n",
    "        \n",
    "        # 'D_wlen_median': doc_wlens.median(),\n",
    "        \n",
    "        #? maybe don't need to keep the literal word lengths for stats above doc level?\n",
    "        'D_wlens': doc_wlens\n",
    "\n",
    "    }\n",
    "    doc_dict.update(doc_add)\n",
    "    doc_dict = describe_word_level_series(doc_lemmas, 'D_lmm')\n",
    "    doc_dict = describe_word_level_series(doc_wlens, 'D_wlen')\n",
    "    \n",
    "    d_dicts.append(doc_dict)\n",
    "    \n",
    "d_stats = pd.DataFrame(d_dicts).convert_dtypes()\n",
    "d_stats = d_stats.assign(D_id=d_stats.D_id.astype('string')).set_index('D_id')\n",
    "d_stats.columns = d_stats.columns.str.replace('50%', 'median').str.replace('freq', 'topfreq')\n",
    "d_stats.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       D_lemmas : object  <class 'pandas.core.series.Series'>\n",
      "D_lemmas_concat : string  <class 'str'>\n",
      "        D_wlens : object  <class 'pandas.core.series.Series'>\n",
      "      D_lmm_top : string  <class 'str'>\n",
      ">> memory usage <<\n",
      "Index              728\n",
      "D_lemmas           728\n",
      "D_lemmas_concat    728\n",
      "D_wlens            728\n",
      "D_lmm_top          728\n"
     ]
    }
   ],
   "source": [
    "def print_col_info(df):\n",
    "    width = max(len(c) for c in df.columns)\n",
    "    for c in df.columns:\n",
    "        print(\n",
    "            f'{c.rjust(width)} : {str(df[c].dtype).ljust(8)}{type(df[c][0])}')\n",
    "    print('>> memory usage <<\\n', df.memory_usage('deep').to_string(), sep='')\n",
    "print_col_info(d_stats.loc[:,d_stats.dtypes.astype('string').str.startswith(('obj', 'str'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 91 entries, pcc_eng_val_1.0001_x00001 to pcc_eng_val_1.0091_x00145\n",
      "Data columns (total 30 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   D_Swrd_mean      91 non-null     Float64\n",
      " 1   D_Swrd_std       89 non-null     Float64\n",
      " 2   D_Swrd_min       91 non-null     Int64  \n",
      " 3   D_Swrd_25%       91 non-null     Float64\n",
      " 4   D_Swrd_median    91 non-null     Float64\n",
      " 5   D_Swrd_75%       91 non-null     Float64\n",
      " 6   D_Swrd_max       91 non-null     Int64  \n",
      " 7   D_Swrd_total     91 non-null     Int64  \n",
      " 8   D_Schr_mean      91 non-null     Float64\n",
      " 9   D_Schr_std       89 non-null     Float64\n",
      " 10  D_Schr_min       91 non-null     Int64  \n",
      " 11  D_Schr_25%       91 non-null     Float64\n",
      " 12  D_Schr_median    91 non-null     Float64\n",
      " 13  D_Schr_75%       91 non-null     Float64\n",
      " 14  D_Schr_max       91 non-null     Int64  \n",
      " 15  D_Schr_total     91 non-null     Int64  \n",
      " 16  D_snt_count      91 non-null     Int64  \n",
      " 17  D_lemmas         91 non-null     object \n",
      " 18  D_lemmas_concat  91 non-null     string \n",
      " 19  D_wlens          91 non-null     object \n",
      " 20  D_lmm_unique     91 non-null     Int64  \n",
      " 21  D_lmm_top        91 non-null     string \n",
      " 22  D_lmm_topfreq    91 non-null     Int64  \n",
      " 23  D_wlen_mean      91 non-null     Float64\n",
      " 24  D_wlen_std       91 non-null     Float64\n",
      " 25  D_wlen_min       91 non-null     Int64  \n",
      " 26  D_wlen_25%       91 non-null     Float64\n",
      " 27  D_wlen_median    91 non-null     Float64\n",
      " 28  D_wlen_75%       91 non-null     Float64\n",
      " 29  D_wlen_max       91 non-null     Int64  \n",
      "dtypes: Float64(15), Int64(11), object(2), string(2)\n",
      "memory usage: 24.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# print_col_info(d_stats.convert_dtypes())\n",
    "d_stats.info(memory_usage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 91 entries, pcc_eng_val_1.0001_x00001 to pcc_eng_val_1.0091_x00145\n",
      "Data columns (total 30 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   D_Swrd_mean      91 non-null     Float32\n",
      " 1   D_Swrd_std       89 non-null     Float32\n",
      " 2   D_Swrd_min       91 non-null     Int8   \n",
      " 3   D_Swrd_25%       91 non-null     Float32\n",
      " 4   D_Swrd_median    91 non-null     Float32\n",
      " 5   D_Swrd_75%       91 non-null     Float32\n",
      " 6   D_Swrd_max       91 non-null     Int8   \n",
      " 7   D_Swrd_total     91 non-null     Int16  \n",
      " 8   D_Schr_mean      91 non-null     Float32\n",
      " 9   D_Schr_std       89 non-null     Float32\n",
      " 10  D_Schr_min       91 non-null     Int16  \n",
      " 11  D_Schr_25%       91 non-null     Float32\n",
      " 12  D_Schr_median    91 non-null     Float32\n",
      " 13  D_Schr_75%       91 non-null     Float32\n",
      " 14  D_Schr_max       91 non-null     Int16  \n",
      " 15  D_Schr_total     91 non-null     Int16  \n",
      " 16  D_snt_count      91 non-null     Int16  \n",
      " 17  D_lemmas         91 non-null     object \n",
      " 18  D_lemmas_concat  91 non-null     string \n",
      " 19  D_wlens          91 non-null     object \n",
      " 20  D_lmm_unique     91 non-null     Int16  \n",
      " 21  D_lmm_top        91 non-null     string \n",
      " 22  D_lmm_topfreq    91 non-null     Int8   \n",
      " 23  D_wlen_mean      91 non-null     Float32\n",
      " 24  D_wlen_std       91 non-null     Float32\n",
      " 25  D_wlen_min       91 non-null     Int8   \n",
      " 26  D_wlen_25%       91 non-null     Float32\n",
      " 27  D_wlen_median    91 non-null     Float32\n",
      " 28  D_wlen_75%       91 non-null     Float32\n",
      " 29  D_wlen_max       91 non-null     Int8   \n",
      "dtypes: Float32(15), Int16(6), Int8(5), object(2), string(2)\n",
      "memory usage: 12.7+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# * FLOATS\n",
    "is_float = d_stats.dtypes.astype('string').str.startswith(('float', 'Float'))\n",
    "\n",
    "# print('\\nfloats unchanged')\n",
    "# print_col_info(d_stats.loc[:,is_float])\n",
    "\n",
    "#> downcast float\n",
    "# print('\\nfloat Downcast')\n",
    "dwncst_df = d_stats.copy()\n",
    "dwncst_df.loc[:, is_float] = dwncst_df.loc[:, is_float].apply(\n",
    "    lambda c: pd.to_numeric(c, downcast='float'))\n",
    "# print_col_info(dwncst_df.loc[:, is_float])\n",
    "# \n",
    "# # * INTEGERS\n",
    "is_int = d_stats.dtypes.astype('string').str.startswith(('int','Int'))\n",
    "\n",
    "# print('\\nintegers unchanged')\n",
    "# print_col_info(d_stats.loc[:,is_int])\n",
    "# \n",
    "# #> downcast unsigned\n",
    "# print('\\nUNsigned Downcast')\n",
    "# dwncst_uint_df = dwncst_df.copy()\n",
    "# dwncst_uint_df.loc[:, is_int] = dwncst_uint_df.loc[:, is_int].apply(\n",
    "#     lambda c: pd.to_numeric(c, downcast='unsigned'))\n",
    "# print_col_info(dwncst_uint_df.loc[:, is_int])\n",
    "# \n",
    "# #> downcast signed\n",
    "# print('\\nsigned downcast')\n",
    "# dwncst_int_df = dwncst_df.copy()\n",
    "# dwncst_int_df.loc[:, is_int] = dwncst_int_df.loc[:, is_int].apply(\n",
    "#     lambda c: pd.to_numeric(c, downcast='signed'))\n",
    "# print_col_info(dwncst_int_df.loc[:, is_int])\n",
    "\n",
    "# float_d_stats = d_stats.loc[:,d_stats.dtypes.str.startswith(('float','Float'))]\n",
    "# float_downcast = float_d_stats.apply(lambda c: pd.to_numeric(c, downcast='float'))\n",
    "# int_d_stats = d_stats.loc[:,d_stats.dtypes.str.startswith(('int','Int'))]\n",
    "# int_downcast = int_d_stats\n",
    "\n",
    "dwncst_df.loc[:, is_int] = dwncst_df.loc[:, is_int].apply(\n",
    "    lambda c: pd.to_numeric(c, downcast='integer'))\n",
    "\n",
    "dwncst_df.info(memory_usage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_stats = dwncst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No metrics are identical/redundant.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>D_id</th>\n",
       "      <th>pcc_eng_val_1.0001_x00001</th>\n",
       "      <th>pcc_eng_val_1.0002_x00002</th>\n",
       "      <th>pcc_eng_val_1.0003_x00005</th>\n",
       "      <th>pcc_eng_val_1.0004_x00006</th>\n",
       "      <th>pcc_eng_val_1.0005_x00007</th>\n",
       "      <th>pcc_eng_val_1.0006_x00008</th>\n",
       "      <th>pcc_eng_val_1.0007_x00009</th>\n",
       "      <th>pcc_eng_val_1.0008_x00010</th>\n",
       "      <th>pcc_eng_val_1.0009_x00011</th>\n",
       "      <th>pcc_eng_val_1.0010_x00012</th>\n",
       "      <th>...</th>\n",
       "      <th>pcc_eng_val_1.0082_x00128</th>\n",
       "      <th>pcc_eng_val_1.0083_x00130</th>\n",
       "      <th>pcc_eng_val_1.0084_x00131</th>\n",
       "      <th>pcc_eng_val_1.0085_x00132</th>\n",
       "      <th>pcc_eng_val_1.0086_x00136</th>\n",
       "      <th>pcc_eng_val_1.0087_x00137</th>\n",
       "      <th>pcc_eng_val_1.0088_x00140</th>\n",
       "      <th>pcc_eng_val_1.0089_x00141</th>\n",
       "      <th>pcc_eng_val_1.0090_x00144</th>\n",
       "      <th>pcc_eng_val_1.0091_x00145</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pcc_eng_val_1.0001_x00001, pcc_eng_val_1.0002_x00002, pcc_eng_val_1.0003_x00005, pcc_eng_val_1.0004_x00006, pcc_eng_val_1.0005_x00007, pcc_eng_val_1.0006_x00008, pcc_eng_val_1.0007_x00009, pcc_eng_val_1.0008_x00010, pcc_eng_val_1.0009_x00011, pcc_eng_val_1.0010_x00012, pcc_eng_val_1.0011_x00017, pcc_eng_val_1.0012_x00018, pcc_eng_val_1.0013_x00019, pcc_eng_val_1.0014_x00021, pcc_eng_val_1.0015_x00022, pcc_eng_val_1.0016_x00024, pcc_eng_val_1.0017_x00025, pcc_eng_val_1.0018_x00026, pcc_eng_val_1.0019_x00028, pcc_eng_val_1.0020_x00029, pcc_eng_val_1.0021_x00030, pcc_eng_val_1.0022_x00031, pcc_eng_val_1.0023_x00032, pcc_eng_val_1.0024_x00037, pcc_eng_val_1.0025_x00039, pcc_eng_val_1.0026_x00040, pcc_eng_val_1.0027_x00041, pcc_eng_val_1.0028_x00043, pcc_eng_val_1.0029_x00044, pcc_eng_val_1.0030_x00045, pcc_eng_val_1.0031_x00046, pcc_eng_val_1.0032_x00047, pcc_eng_val_1.0033_x00048, pcc_eng_val_1.0034_x00050, pcc_eng_val_1.0035_x00051, pcc_eng_val_1.0036_x00055, pcc_eng_val_1.0037_x00056, pcc_eng_val_1.0038_x00057, pcc_eng_val_1.0039_x00058, pcc_eng_val_1.0040_x00060, pcc_eng_val_1.0041_x00062, pcc_eng_val_1.0042_x00063, pcc_eng_val_1.0043_x00064, pcc_eng_val_1.0044_x00067, pcc_eng_val_1.0045_x00070, pcc_eng_val_1.0046_x00071, pcc_eng_val_1.0047_x00072, pcc_eng_val_1.0048_x00073, pcc_eng_val_1.0049_x00074, pcc_eng_val_1.0050_x00075, pcc_eng_val_1.0051_x00077, pcc_eng_val_1.0052_x00080, pcc_eng_val_1.0053_x00081, pcc_eng_val_1.0054_x00082, pcc_eng_val_1.0055_x00083, pcc_eng_val_1.0056_x00086, pcc_eng_val_1.0057_x00087, pcc_eng_val_1.0058_x00088, pcc_eng_val_1.0059_x00089, pcc_eng_val_1.0060_x00090, pcc_eng_val_1.0061_x00091, pcc_eng_val_1.0062_x00092, pcc_eng_val_1.0063_x00093, pcc_eng_val_1.0064_x00096, pcc_eng_val_1.0065_x00097, pcc_eng_val_1.0066_x00098, pcc_eng_val_1.0067_x00099, pcc_eng_val_1.0068_x00101, pcc_eng_val_1.0069_x00103, pcc_eng_val_1.0070_x00104, pcc_eng_val_1.0071_x00107, pcc_eng_val_1.0072_x00108, pcc_eng_val_1.0073_x00110, pcc_eng_val_1.0074_x00111, pcc_eng_val_1.0075_x00112, pcc_eng_val_1.0076_x00114, pcc_eng_val_1.0077_x00115, pcc_eng_val_1.0078_x00117, pcc_eng_val_1.0079_x00119, pcc_eng_val_1.0080_x00120, pcc_eng_val_1.0081_x00125, pcc_eng_val_1.0082_x00128, pcc_eng_val_1.0083_x00130, pcc_eng_val_1.0084_x00131, pcc_eng_val_1.0085_x00132, pcc_eng_val_1.0086_x00136, pcc_eng_val_1.0087_x00137, pcc_eng_val_1.0088_x00140, pcc_eng_val_1.0089_x00141, pcc_eng_val_1.0090_x00144, pcc_eng_val_1.0091_x00145]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 91 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashable_stats = d_stats.loc[:, d_stats.dtypes != 'object']\n",
    "trans_d_df = hashable_stats.transpose()\n",
    "same_vals = trans_d_df.duplicated(keep=False)\n",
    "equivalent_metrics = trans_d_df.loc[same_vals, :]\n",
    "if equivalent_metrics.empty: \n",
    "    print('No metrics are identical/redundant.')\n",
    "else: \n",
    "    print('These metrics are redundant:', ''.join('\\n'+i for i in equivalent_metrics.index))\n",
    "equivalent_metrics.sort_values(equivalent_metrics.columns[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No other metrics are similar enough to collapse entirely.\n"
     ]
    }
   ],
   "source": [
    "round_transdf = hashable_stats.transpose().round()\n",
    "almost_same = round_transdf.duplicated(keep=False)\n",
    "similar_metrics = round_transdf.loc[almost_same, :]\n",
    "similar_metrics = similar_metrics.loc[~similar_metrics.index.isin(\n",
    "    equivalent_metrics.index), :]\n",
    "if similar_metrics.empty:\n",
    "    print('No other metrics are similar enough to collapse entirely.')\n",
    "else:\n",
    "    print('These metrics could be collapsed:')\n",
    "    similar_metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dev-sanpi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a82d64a7e868996b1805260a9c82ff1f9f38ed6473139e2deee21ec8e5331945"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
