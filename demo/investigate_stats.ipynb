{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to investigate getting stats for puddin files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import statistics as st\n",
    "import pyconll\n",
    "from collections import namedtuple\n",
    "\n",
    "DATA_GRP = 'val'\n",
    "DATA_DIR = Path('data/puddin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_code = f'Pcc{DATA_GRP[:2].capitalize()}'\n",
    "group_dir = DATA_DIR.joinpath(f'{data_code}.conll')\n",
    "# for group_info_file in DATA_DIR.joinpath('info/validation_by_group/status-overview/'\n",
    "#                                          ).glob('*status-info*pkl*'):\n",
    "#     # for testing\n",
    "#     if not group_info_file.stem.startswith(data_code):\n",
    "#         continue\n",
    "#     else:\n",
    "#         group_info = pd.read_pickle(group_info_file)\n",
    "#         break\n",
    "# group_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had been using `egrep` to more quickly generate counts for different units. However, I don't think that is the most effective way to go about getting counts for anything below the conllu file level; i.e. per document or per sentence stats. Those will need to employ `pyconll` and actually parse the conllu formatting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_contents(conllu_path):\n",
    "    reader = pyconll.iter_from_file(conllu_path)\n",
    "    conllu_df = pd.DataFrame(reader)\n",
    "    return conllu_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not group_dir.is_dir():\n",
    "    print('CANNOT FIND CONLLU DIR FOR', data_code)\n",
    "else:\n",
    "    stem_col = group_info.conllu_stem\n",
    "    for stem in stem_col.unique():\n",
    "        conllu_path = group_dir.joinpath(f'{stem}.conllu')\n",
    "        if conllu_path.is_file():# and conllu_path.stat().st_size > 0:\n",
    "\n",
    "            print(f'conllu: {conllu_path}')\n",
    "        # else:\n",
    "        #     print(f'{conllu_path} does not exist, or is not a file.')\n",
    "        #> this should go within loop, but only doing one for devel so pulling it out\n",
    "        # d_counts = count_contents(conllu_path)\n",
    "    print(f'Counting data in {conllu_path}...')\n",
    "    # d_counts = count_contents(conllu_path)\n",
    "\n",
    "# > developing method for counting with pyconll object with only last path of loop\n",
    "# conllu_reader = pyconll.iter_from_file(conllu_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seeing if pandas can do anything with the pyconll object..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_sentences(conll_df):\n",
    "\n",
    "#     for i in range(len(conll_df)):\n",
    "#         sentence = []\n",
    "#         for x in range(len(conll_df.columns)):\n",
    "#             word = conll_df.iat[i,x]\n",
    "#             if word:\n",
    "#                 sentence.append(word)\n",
    "#         # print(*[w.form for w in sentence])\n",
    "#         yield sentence\n",
    "\n",
    "\n",
    "# sentences_gen = gen_sentences(s_df)\n",
    "# for s in sentences_gen:\n",
    "#     print(*[w.form for w in s])\n",
    "# # df = pd.DataFrame(pyconll.iter_from_file(conllu_path))\n",
    "# # sentence_gen = gen_sences(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is no better--worse even probably--than just iterating through the pyconll object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_col_info(df):\n",
    "    width = max(len(c) for c in df.columns)\n",
    "    for c in df.columns:\n",
    "        print(\n",
    "            f'{c.rjust(width)} : {str(df[c].dtype).ljust(8)}{type(df[c][0])}')\n",
    "    mem_use = df.memory_usage('deep')\n",
    "    print('>> memory usage <<\\n',mem_use.to_string(), sep='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tuple = namedtuple('sent_counts',\n",
    "                        ['s_id', 's_txt', 's_wrd', 's_chr', 's_wlen_list', 's_md_wlen', 's_mn_wlen', 's_cpw'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sentence_info(conllu_path):\n",
    "\n",
    "    for sentence in pyconll.iter_from_file(conllu_path):\n",
    "        word_lengths = [len(w.form)\n",
    "                        for w in sentence._tokens if w.deprel != 'punct']\n",
    "        # print(word_lengths)\n",
    "        word_count = len(word_lengths)\n",
    "        md_word_len = st.median(word_lengths)\n",
    "        mn_word_len = st.mean(word_lengths)\n",
    "        char_count = sum(word_lengths)\n",
    "        char_per_word = char_count/word_count\n",
    "        yield sent_tuple(sentence.id, sentence.text, word_count, char_count, word_lengths,\n",
    "                         md_word_len, mn_word_len, char_per_word)\n",
    "\n",
    "\n",
    "# conllu_counts_df = pd.DataFrame(gen_sentence_info(conllu_path))\n",
    "# conllu_counts_df.head()\n",
    "s_df = pd.DataFrame(gen_sentence_info(\n",
    "    'data/puddin/PccSa1.conll/pcc_eng_sample-1-01.conllu'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_cols = s_df.columns.str.endswith(('id', 'xt'))\n",
    "s_df.loc[:, str_cols] = s_df.loc[:, str_cols].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_id_split = s_df.s_id.str.rsplit('_', 1)\n",
    "\n",
    "s_df = s_df.assign(d_id=sent_id_split.str.get(0),\n",
    "                   #  s_ix = sent_id_split.str.get(1),\n",
    "                   ).convert_dtypes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial\n",
      "s_wrd : Int64   <class 'numpy.int64'>\n",
      "s_chr : Int64   <class 'numpy.int64'>\n",
      ">> memory usage <<\n",
      "Index     128\n",
      "s_wrd    1521\n",
      "s_chr    1521\n",
      "\n",
      "UNsigned Downcast\n",
      "s_wrd : UInt8   <class 'numpy.uint8'>\n",
      "s_chr : UInt8   <class 'numpy.uint8'>\n",
      ">> memory usage <<\n",
      "Index    128\n",
      "s_wrd    338\n",
      "s_chr    338\n",
      "\n",
      "signed downcast\n",
      "s_wrd : Int8    <class 'numpy.int8'>\n",
      "s_chr : Int16   <class 'numpy.int16'>\n",
      ">> memory usage <<\n",
      "Index    128\n",
      "s_wrd    338\n",
      "s_chr    507\n"
     ]
    }
   ],
   "source": [
    "count_cols = s_df.columns.str.endswith(('chr', 'wrd'))\n",
    "print('Initial')\n",
    "print_col_info(s_df.loc[:, count_cols])\n",
    "\n",
    "# downcast unsigned\n",
    "print('\\nUNsigned Downcast')\n",
    "uint_df = s_df.copy()\n",
    "uint_df.loc[:, count_cols] = uint_df.loc[:, count_cols].apply(\n",
    "    lambda c: pd.to_numeric(c, downcast='unsigned'))\n",
    "print_col_info(uint_df.loc[:, count_cols])\n",
    "\n",
    "#downcast signed\n",
    "print('\\nsigned downcast')\n",
    "int_df = s_df.copy()\n",
    "int_df.loc[:, count_cols] = int_df.loc[:, count_cols].apply(\n",
    "    lambda c: pd.to_numeric(c, downcast='signed'))\n",
    "print_col_info(int_df.loc[:, count_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by document and add stats at document level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_stats(sentence_df):\n",
    "    \n",
    "    d_dicts = []\n",
    "    d_tups = []\n",
    "    d_sers = []\n",
    "    print(f'\\n### input data type: {sentence_df.s_chr.dtype}')\n",
    "    for doc, gdf in sentence_df.groupby('d_id'):\n",
    "        # print(doc)\n",
    "        # pprint(gdf.s_txt.to_list())\n",
    "        s_chr = gdf.s_chr\n",
    "        # print(s_chr.dtype)\n",
    "\n",
    "        d_chr = s_chr.sum()\n",
    "        d_mn_s_chr = s_chr.mean()\n",
    "        d_md_s_chr = s_chr.median()\n",
    "        d_min_s_chr = s_chr.min()\n",
    "        # d_max_s_chr =\n",
    "        # print(f'least characters in a sentence: {d_min_s_chr}',f'most characters in a sentence: {d_max_s_chr}', sep='\\n')\n",
    "\n",
    "        s_wrd = gdf.s_wrd\n",
    "        # print(s_wrd.dtype)\n",
    "        # pprint(s_wrd.to_list())\n",
    "        d_wrd = s_wrd.sum()\n",
    "        d_mn_s_wrd = s_wrd.mean()\n",
    "        d_md_s_wrd = s_wrd.median()\n",
    "        d_min_s_wrd = s_wrd.min()\n",
    "        d_max_s_wrd = s_wrd.max()\n",
    "        # print(f'least words in a sentence: {d_min_s_wrd}',f'most words in a sentence: {d_max_s_wrd}', sep='\\n',end='\\n\\n')\n",
    "\n",
    "        d_snt = len(gdf)\n",
    "\n",
    "        d_mn_s_cpw = gdf.s_cpw.mean()\n",
    "        d_mn_s_mn_wlen = gdf.s_mn_wlen.mean()  # this should be same as above\n",
    "        d_mn_s_md_wlen = gdf.s_md_wlen.mean()\n",
    "\n",
    "        d_md_s_md_wlen = gdf.s_md_wlen.median()\n",
    "\n",
    "        d_mo_s_md_wlen = gdf.s_md_wlen.mode()\n",
    "        ddict = {\n",
    "            'd_id': doc,        # document id\n",
    "            # total characters in doc (~ doc length in characters)\n",
    "            'd_chr': d_chr,\n",
    "            'd_mn_s_chr': d_mn_s_chr,  # mean sent length in characters\n",
    "            'd_md_s_chr': d_md_s_chr,  # median sent length in characters\n",
    "            # total words in doc (~ doc length in words)\n",
    "            'd_wrd': d_wrd,\n",
    "            'd_mn_s_wrd': d_mn_s_wrd,  # mean sent length in words\n",
    "            'd_md_s_wrd': d_md_s_wrd,  # median sent length in words\n",
    "            # total sentences in doc (~ doc length in sentences)\n",
    "            'd_snt': d_snt,\n",
    "            # total char in doc / total words in doc # * same as mean(d_chr/d_wrd)?\n",
    "            'd_cpw': d_chr/d_wrd,\n",
    "            # total words in doc / total sentences in doc # * same as mean(d_wrd/d_snt)?\n",
    "            'd_wps': d_wrd/d_snt,\n",
    "            # mean of char/word value for all sentences in doc ~ mean word length\n",
    "            'd_mn_s_cpw': d_mn_s_cpw,\n",
    "\n",
    "            'd_mn_s_mn_wlen': d_mn_s_mn_wlen,  # doc mean of sent mean word length\n",
    "            'd_mn_s_md_wlen': d_mn_s_md_wlen,  # doc mean of sent median word length\n",
    "            'd_md_s_md_wlen': d_md_s_md_wlen,  # doc median of sent median word length\n",
    "\n",
    "            #! causes issues because not always a single value\n",
    "            # 'd_mo_s_md_wlen': d_mo_s_md_wlen,  # doc mode of sent median word length\n",
    "\n",
    "            'd_min_s_chr': d_min_s_chr,\n",
    "            'd_max_s_chr': s_chr.max(),\n",
    "\n",
    "            'd_min_s_wrd': d_min_s_wrd,\n",
    "            'd_max_s_wrd': d_max_s_wrd,\n",
    "        }\n",
    "        # print(ddict['d_max_s_chr'], end='\\n\\n')\n",
    "\n",
    "        d_dicts.append(ddict)\n",
    "    return d_dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### input data type: Int64\n",
      "\n",
      "# Dict Values and Types:\n",
      "108\t<class 'numpy.int64'>\n",
      "90\t<class 'numpy.int64'>\n",
      "67\t<class 'numpy.int64'>\n",
      "57\t<class 'numpy.int64'>\n",
      "83\t<class 'numpy.int64'>\n",
      "164\t<class 'numpy.int64'>\n",
      "111\t<class 'numpy.int64'>\n",
      "197\t<class 'numpy.int64'>\n",
      "185\t<class 'numpy.int64'>\n",
      "249\t<class 'numpy.int64'>\n",
      "119\t<class 'numpy.int64'>\n",
      "138\t<class 'numpy.int64'>\n",
      "\n",
      "# Results when converted to dataframe:\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'accurate_max_char_int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/arh234/projects/puddin/demo/investigate_stats.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/arh234/projects/puddin/demo/investigate_stats.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m actual_max_chr \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(d[\u001b[39m'\u001b[39m\u001b[39md_max_s_chr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m doc_dicts)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/arh234/projects/puddin/demo/investigate_stats.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m mod_dstats \u001b[39m=\u001b[39m d_stats\u001b[39m.\u001b[39massign(given_max_char\u001b[39m=\u001b[39md_stats\u001b[39m.\u001b[39md_max_s_chr,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/arh234/projects/puddin/demo/investigate_stats.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m               accurate_max_char_int\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mto_numeric(actual_max_chr, downcast\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigned\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/arh234/projects/puddin/demo/investigate_stats.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(mod_dstats\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/arh234/projects/puddin/demo/investigate_stats.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m       \u001b[39m.\u001b[39massign(accurate_max_char_uint\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mto_numeric(\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/arh234/projects/puddin/demo/investigate_stats.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m           d_stats\u001b[39m.\u001b[39;49maccurate_max_char_int, downcast\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39munsigned\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/arh234/projects/puddin/demo/investigate_stats.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m       \u001b[39m.\u001b[39msort_values(\u001b[39m'\u001b[39m\u001b[39maccurate_max_char\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/arh234/projects/puddin/demo/investigate_stats.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m       \u001b[39m.\u001b[39mloc[:, [\u001b[39m'\u001b[39m\u001b[39mgiven_max_char\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39maccurate_max_char\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/arh234/projects/puddin/demo/investigate_stats.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m       \u001b[39m.\u001b[39mto_string())\n",
      "File \u001b[0;32m~/anaconda3/envs/dev-sanpi/lib/python3.10/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5568\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5569\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5570\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5571\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5572\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5573\u001b[0m ):\n\u001b[1;32m   5574\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5575\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'accurate_max_char_int'"
     ]
    }
   ],
   "source": [
    "for df in [s_df, uint_df, int_df]:\n",
    "    doc_dicts = get_doc_stats(df)\n",
    "    print('\\n# Dict Values and Types:')\n",
    "    for chr_val in (d['d_max_s_chr'] for d in doc_dicts): \n",
    "        print(chr_val, type(chr_val), sep='\\t')\n",
    "    d_stats = pd.DataFrame(doc_dicts)\n",
    "    print('\\n# Results when converted to dataframe:')\n",
    "    print(f'dtype: {d_stats.d_max_s_chr.dtype}')\n",
    "    d_stats.d_max_s_chr\n",
    "    \n",
    "    actual_max_chr = pd.Series(d['d_max_s_chr'] for d in doc_dicts)\n",
    "    mod_dstats = d_stats.assign(given_max_char=d_stats.d_max_s_chr,\n",
    "                  accurate_max_char_int=pd.to_numeric(actual_max_chr, downcast='signed'))\n",
    "    print(mod_dstats\n",
    "          .assign(accurate_max_char_uint=pd.to_numeric(\n",
    "              d_stats.accurate_max_char_int, downcast='unsigned'))\n",
    "          .sort_values('accurate_max_char')\n",
    "          .loc[:, ['given_max_char','accurate_max_char']]\n",
    "          .to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylint: disable=missing-module-docstring\n",
    "trans_d_df = d_stats.transpose()\n",
    "trans_d_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_vals = trans_d_df.duplicated(keep=False)\n",
    "equiv_metric = trans_d_df.loc[same_vals, :]\n",
    "equiv_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_transdf = d_stats.set_index('d_id').transpose().round()\n",
    "round_transdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "almost_same = round_transdf.duplicated(keep=False)\n",
    "similar_metric = round_transdf.loc[almost_same, :]\n",
    "similar_metric.loc[~similar_metric.index.isin(equiv_metric.index), :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# by_d_df = d_stats.loc[:,\n",
    "#     # columns to perpetuate\n",
    "#     d_stats.columns.str.startswith('doc')\n",
    "# ].round(3)\n",
    "# by_d_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing if it comes out the same to average on top of averages or just do the calculation directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any(by_d_df.d_mean_s_avg_word_len != by_d_df.d_char_per_word)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dev-sanpi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a82d64a7e868996b1805260a9c82ff1f9f38ed6473139e2deee21ec8e5331945"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
