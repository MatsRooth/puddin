{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to investigate getting stats for puddin files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "#> imports\n",
    "import pandas as pd\n",
    "# import statistics as st\n",
    "import pyconll\n",
    "\n",
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "#> constants\n",
    "# DATA_GRP = 'val'\n",
    "# DATA_DIR = Path('data/puddin')\n",
    "CONLLU_SAMPLE_PATH = Path('/home/arh234/projects/puddin/demo/data/puddin/PccSa1.conll/pcc_eng_sample-1-01.conllu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_col_info(df):\n",
    "    # width = max(len(c) for c in df.columns)\n",
    "    # for c in df.columns:\n",
    "    #     print(\n",
    "    #         f'{c.rjust(width)} : {str(df[c].dtype).ljust(8)}{type(df[c][0])}')\n",
    "    # print('>> memory usage <<\\n', df.memory_usage('deep').to_string(), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had been using `egrep` to more quickly generate counts for different units. However, I don't think that is the most effective way to go about getting counts for anything below the conllu file level; i.e. per document or per sentence stats. Those will need to employ `pyconll` and actually parse the conllu formatting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sentence_info(conllu_path):\n",
    "\n",
    "    sent_tuple = namedtuple(\n",
    "        'sent_counts',\n",
    "        ['sid', 'did', 'txt',\n",
    "         'lmm_list', 'wrd_list', \n",
    "         #? is `wlen_list` truly needed?\n",
    "         'wlen_list',\n",
    "         'wrd_count', 'chr_count',\n",
    "         #//  'wlen_median',\n",
    "         'wlen_mean'])\n",
    "\n",
    "    doc = None\n",
    "    for sentence in pyconll.iter_from_file(conllu_path):\n",
    "\n",
    "        if sentence.meta_present('newdoc id'):\n",
    "            doc = sentence.meta_value('newdoc id')\n",
    "            print(doc)\n",
    "        elif not doc:\n",
    "            print('! WARNING: doc info not found!')\n",
    "        elif not sentence.id.startswith(doc):\n",
    "            print('~!~ WARNING: doc and sentence ids do not match!')\n",
    "        # print(sentence.text)\n",
    "\n",
    "        #* NOTE: this excludes all punctuation symbols!\n",
    "        tok_objects = [\n",
    "            tok for tok in sentence._tokens if tok.deprel != 'punct']\n",
    "        lemmas = [tok.lemma for tok in tok_objects]\n",
    "        words = [tok.form for tok in tok_objects]\n",
    "        word_lengths = [len(word) for word in words]\n",
    "        # print(word_lengths)\n",
    "        word_count = len(word_lengths)\n",
    "        #// md_word_len = st.median(word_lengths)\n",
    "        char_count = sum(word_lengths)\n",
    "        char_per_word = char_count/word_count\n",
    "        yield sent_tuple(sentence.id, doc, sentence.text,\n",
    "                         lemmas, words, word_lengths,\n",
    "                         word_count, char_count,\n",
    "                         #//  md_word_len,\n",
    "                         char_per_word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcc_eng_sample-1_1.01_x01\n",
      "pcc_eng_sample-1_1.02_x02\n",
      "pcc_eng_sample-1_1.03_x04\n",
      "pcc_eng_sample-1_1.04_x07\n",
      "pcc_eng_sample-1_1.05_x08\n",
      "pcc_eng_sample-1_1.06_x09\n",
      "pcc_eng_sample-1_1.07_x11\n",
      "pcc_eng_sample-1_1.08_x12\n",
      "pcc_eng_sample-1_1.09_x13\n",
      "pcc_eng_sample-1_1.10_x16\n",
      "pcc_eng_sample-1_1.11_x18\n",
      "pcc_eng_sample-1_1.12_x19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>txt</th>\n",
       "      <th>lmm_list</th>\n",
       "      <th>wrd_list</th>\n",
       "      <th>wlen_list</th>\n",
       "      <th>wrd_count</th>\n",
       "      <th>chr_count</th>\n",
       "      <th>wlen_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pcc_eng_sample-1_1.03_x04_6</th>\n",
       "      <td>pcc_eng_sample-1_1.03_x04</td>\n",
       "      <td>The bag is made after a template from Stinne K...</td>\n",
       "      <td>[the, bag, be, make, after, a, template, from,...</td>\n",
       "      <td>[The, bag, is, made, after, a, template, from,...</td>\n",
       "      <td>[3, 3, 2, 4, 5, 1, 8, 4, 6, 5]</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>4.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcc_eng_sample-1_1.07_x11_05</th>\n",
       "      <td>pcc_eng_sample-1_1.07_x11</td>\n",
       "      <td>YOUR WEBSITE.</td>\n",
       "      <td>[you, website]</td>\n",
       "      <td>[YOUR, WEBSITE]</td>\n",
       "      <td>[4, 7]</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcc_eng_sample-1_1.12_x19_8</th>\n",
       "      <td>pcc_eng_sample-1_1.12_x19</td>\n",
       "      <td>The UN health agency says virus samples from t...</td>\n",
       "      <td>[the, UN, health, agency, say, virus, sample, ...</td>\n",
       "      <td>[The, UN, health, agency, says, virus, samples...</td>\n",
       "      <td>[3, 2, 6, 6, 4, 5, 7, 4, 3, 7, 4, 6, 9, 2, 5, ...</td>\n",
       "      <td>27</td>\n",
       "      <td>120</td>\n",
       "      <td>4.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    did  \\\n",
       "sid                                                       \n",
       "pcc_eng_sample-1_1.03_x04_6   pcc_eng_sample-1_1.03_x04   \n",
       "pcc_eng_sample-1_1.07_x11_05  pcc_eng_sample-1_1.07_x11   \n",
       "pcc_eng_sample-1_1.12_x19_8   pcc_eng_sample-1_1.12_x19   \n",
       "\n",
       "                                                                            txt  \\\n",
       "sid                                                                               \n",
       "pcc_eng_sample-1_1.03_x04_6   The bag is made after a template from Stinne K...   \n",
       "pcc_eng_sample-1_1.07_x11_05                                      YOUR WEBSITE.   \n",
       "pcc_eng_sample-1_1.12_x19_8   The UN health agency says virus samples from t...   \n",
       "\n",
       "                                                                       lmm_list  \\\n",
       "sid                                                                               \n",
       "pcc_eng_sample-1_1.03_x04_6   [the, bag, be, make, after, a, template, from,...   \n",
       "pcc_eng_sample-1_1.07_x11_05                                     [you, website]   \n",
       "pcc_eng_sample-1_1.12_x19_8   [the, UN, health, agency, say, virus, sample, ...   \n",
       "\n",
       "                                                                       wrd_list  \\\n",
       "sid                                                                               \n",
       "pcc_eng_sample-1_1.03_x04_6   [The, bag, is, made, after, a, template, from,...   \n",
       "pcc_eng_sample-1_1.07_x11_05                                    [YOUR, WEBSITE]   \n",
       "pcc_eng_sample-1_1.12_x19_8   [The, UN, health, agency, says, virus, samples...   \n",
       "\n",
       "                                                                      wlen_list  \\\n",
       "sid                                                                               \n",
       "pcc_eng_sample-1_1.03_x04_6                      [3, 3, 2, 4, 5, 1, 8, 4, 6, 5]   \n",
       "pcc_eng_sample-1_1.07_x11_05                                             [4, 7]   \n",
       "pcc_eng_sample-1_1.12_x19_8   [3, 2, 6, 6, 4, 5, 7, 4, 3, 7, 4, 6, 9, 2, 5, ...   \n",
       "\n",
       "                              wrd_count  chr_count  wlen_mean  \n",
       "sid                                                            \n",
       "pcc_eng_sample-1_1.03_x04_6          10         41   4.100000  \n",
       "pcc_eng_sample-1_1.07_x11_05          2         11   5.500000  \n",
       "pcc_eng_sample-1_1.12_x19_8          27        120   4.444444  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_conll_iter = gen_sentence_info(CONLLU_SAMPLE_PATH)\n",
    "sdf = pd.DataFrame(s_conll_iter).set_index('sid')\n",
    "sdf.sample(3).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count                           169\n",
      "unique                           12\n",
      "top       pcc_eng_sample-1_1.07_x11\n",
      "freq                             41\n",
      "Name: did, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wrd_count</th>\n",
       "      <th>chr_count</th>\n",
       "      <th>wlen_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>169.00</td>\n",
       "      <td>169.00</td>\n",
       "      <td>169.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.04</td>\n",
       "      <td>65.23</td>\n",
       "      <td>4.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.42</td>\n",
       "      <td>44.25</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.00</td>\n",
       "      <td>67.00</td>\n",
       "      <td>4.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.00</td>\n",
       "      <td>249.00</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wrd_count  chr_count  wlen_mean\n",
       "count     169.00     169.00     169.00\n",
       "mean       14.04      65.23       4.85\n",
       "std         9.42      44.25       1.11\n",
       "min         1.00       5.00       2.75\n",
       "25%         5.00      26.00       4.10\n",
       "50%        14.00      67.00       4.71\n",
       "75%        20.00      90.00       5.50\n",
       "max        45.00     249.00       8.50"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sdf.did.describe())\n",
    "sdf.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by document and add stats at document level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['did',\n",
       " 'txt',\n",
       " 'lmm_list',\n",
       " 'wrd_list',\n",
       " 'wlen_list',\n",
       " 'wrd_count',\n",
       " 'chr_count',\n",
       " 'wlen_mean']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D_Swrd_mean</th>\n",
       "      <th>D_Swrd_std</th>\n",
       "      <th>D_Swrd_min</th>\n",
       "      <th>D_Swrd_25%</th>\n",
       "      <th>D_Swrd_50%</th>\n",
       "      <th>D_Swrd_75%</th>\n",
       "      <th>D_Swrd_max</th>\n",
       "      <th>D_Swrd_total</th>\n",
       "      <th>D_Schr_mean</th>\n",
       "      <th>D_Schr_std</th>\n",
       "      <th>...</th>\n",
       "      <th>D_Schr_max</th>\n",
       "      <th>D_Schr_total</th>\n",
       "      <th>D_snt_count</th>\n",
       "      <th>D_wlen_mean</th>\n",
       "      <th>D_lemmas</th>\n",
       "      <th>D_wlens</th>\n",
       "      <th>D_lmm_count</th>\n",
       "      <th>D_lmm_unique</th>\n",
       "      <th>D_lmm_top</th>\n",
       "      <th>D_lmm_freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pcc_eng_sample-1_1.01_x01</th>\n",
       "      <td>9.666667</td>\n",
       "      <td>7.28011</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24</td>\n",
       "      <td>87</td>\n",
       "      <td>42.444444</td>\n",
       "      <td>33.537707</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>382</td>\n",
       "      <td>9</td>\n",
       "      <td>4.390805</td>\n",
       "      <td>0        what\n",
       "1          if\n",
       "2          we\n",
       "3   ...</td>\n",
       "      <td>0     4\n",
       "1     2\n",
       "2     2\n",
       "3     4\n",
       "4     3\n",
       "     ....</td>\n",
       "      <td>87</td>\n",
       "      <td>60</td>\n",
       "      <td>we</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcc_eng_sample-1_1.02_x02</th>\n",
       "      <td>12.0</td>\n",
       "      <td>7.641989</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>18.25</td>\n",
       "      <td>22</td>\n",
       "      <td>72</td>\n",
       "      <td>48.0</td>\n",
       "      <td>29.509321</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>288</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0          I\n",
       "1         be\n",
       "2        get\n",
       "3      ...</td>\n",
       "      <td>0     1\n",
       "1     2\n",
       "2     7\n",
       "3     5\n",
       "4     3\n",
       "     ....</td>\n",
       "      <td>72</td>\n",
       "      <td>53</td>\n",
       "      <td>be</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcc_eng_sample-1_1.03_x04</th>\n",
       "      <td>7.833333</td>\n",
       "      <td>6.853223</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17</td>\n",
       "      <td>47</td>\n",
       "      <td>32.5</td>\n",
       "      <td>26.994444</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>195</td>\n",
       "      <td>6</td>\n",
       "      <td>4.148936</td>\n",
       "      <td>0          page\n",
       "1        Sunday\n",
       "2          Jul...</td>\n",
       "      <td>0      5\n",
       "1      6\n",
       "2      4\n",
       "3      2\n",
       "4      4\n",
       "5...</td>\n",
       "      <td>47</td>\n",
       "      <td>39</td>\n",
       "      <td>be</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcc_eng_sample-1_1.04_x07</th>\n",
       "      <td>11.25</td>\n",
       "      <td>2.629956</td>\n",
       "      <td>9</td>\n",
       "      <td>9.75</td>\n",
       "      <td>10.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>46.5</td>\n",
       "      <td>11.269428</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>186</td>\n",
       "      <td>4</td>\n",
       "      <td>4.133333</td>\n",
       "      <td>0               the\n",
       "1          banknote\n",
       "2     ...</td>\n",
       "      <td>0      3\n",
       "1      9\n",
       "2      5\n",
       "3      2\n",
       "4      4\n",
       "5...</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>the</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcc_eng_sample-1_1.05_x08</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.717798</td>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>60.666667</td>\n",
       "      <td>33.62043</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>182</td>\n",
       "      <td>3</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0        Redstone\n",
       "1             Way\n",
       "2         ...</td>\n",
       "      <td>0      8\n",
       "1      3\n",
       "2      3\n",
       "3      8\n",
       "4      3\n",
       "5...</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>have</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           D_Swrd_mean  D_Swrd_std  D_Swrd_min  D_Swrd_25%  \\\n",
       "D_id                                                                         \n",
       "pcc_eng_sample-1_1.01_x01     9.666667     7.28011           3         4.0   \n",
       "pcc_eng_sample-1_1.02_x02         12.0    7.641989           5         6.0   \n",
       "pcc_eng_sample-1_1.03_x04     7.833333    6.853223           1        1.75   \n",
       "pcc_eng_sample-1_1.04_x07        11.25    2.629956           9        9.75   \n",
       "pcc_eng_sample-1_1.05_x08         14.0    8.717798           4        11.0   \n",
       "\n",
       "                           D_Swrd_50%  D_Swrd_75%  D_Swrd_max  D_Swrd_total  \\\n",
       "D_id                                                                          \n",
       "pcc_eng_sample-1_1.01_x01         9.0        13.0          24            87   \n",
       "pcc_eng_sample-1_1.02_x02         9.5       18.25          22            72   \n",
       "pcc_eng_sample-1_1.03_x04         7.0        13.0          17            47   \n",
       "pcc_eng_sample-1_1.04_x07        10.5        12.0          15            45   \n",
       "pcc_eng_sample-1_1.05_x08        18.0        19.0          20            42   \n",
       "\n",
       "                           D_Schr_mean  D_Schr_std  ...  D_Schr_max  \\\n",
       "D_id                                                ...               \n",
       "pcc_eng_sample-1_1.01_x01    42.444444   33.537707  ...         108   \n",
       "pcc_eng_sample-1_1.02_x02         48.0   29.509321  ...          90   \n",
       "pcc_eng_sample-1_1.03_x04         32.5   26.994444  ...          67   \n",
       "pcc_eng_sample-1_1.04_x07         46.5   11.269428  ...          57   \n",
       "pcc_eng_sample-1_1.05_x08    60.666667    33.62043  ...          83   \n",
       "\n",
       "                           D_Schr_total  D_snt_count  D_wlen_mean  \\\n",
       "D_id                                                                \n",
       "pcc_eng_sample-1_1.01_x01           382            9     4.390805   \n",
       "pcc_eng_sample-1_1.02_x02           288            6          4.0   \n",
       "pcc_eng_sample-1_1.03_x04           195            6     4.148936   \n",
       "pcc_eng_sample-1_1.04_x07           186            4     4.133333   \n",
       "pcc_eng_sample-1_1.05_x08           182            3     4.333333   \n",
       "\n",
       "                                                                    D_lemmas  \\\n",
       "D_id                                                                           \n",
       "pcc_eng_sample-1_1.01_x01  0        what\n",
       "1          if\n",
       "2          we\n",
       "3   ...   \n",
       "pcc_eng_sample-1_1.02_x02  0          I\n",
       "1         be\n",
       "2        get\n",
       "3      ...   \n",
       "pcc_eng_sample-1_1.03_x04  0          page\n",
       "1        Sunday\n",
       "2          Jul...   \n",
       "pcc_eng_sample-1_1.04_x07  0               the\n",
       "1          banknote\n",
       "2     ...   \n",
       "pcc_eng_sample-1_1.05_x08  0        Redstone\n",
       "1             Way\n",
       "2         ...   \n",
       "\n",
       "                                                                     D_wlens  \\\n",
       "D_id                                                                           \n",
       "pcc_eng_sample-1_1.01_x01  0     4\n",
       "1     2\n",
       "2     2\n",
       "3     4\n",
       "4     3\n",
       "     ....   \n",
       "pcc_eng_sample-1_1.02_x02  0     1\n",
       "1     2\n",
       "2     7\n",
       "3     5\n",
       "4     3\n",
       "     ....   \n",
       "pcc_eng_sample-1_1.03_x04  0      5\n",
       "1      6\n",
       "2      4\n",
       "3      2\n",
       "4      4\n",
       "5...   \n",
       "pcc_eng_sample-1_1.04_x07  0      3\n",
       "1      9\n",
       "2      5\n",
       "3      2\n",
       "4      4\n",
       "5...   \n",
       "pcc_eng_sample-1_1.05_x08  0      8\n",
       "1      3\n",
       "2      3\n",
       "3      8\n",
       "4      3\n",
       "5...   \n",
       "\n",
       "                           D_lmm_count  D_lmm_unique D_lmm_top D_lmm_freq  \n",
       "D_id                                                                       \n",
       "pcc_eng_sample-1_1.01_x01           87            60        we          6  \n",
       "pcc_eng_sample-1_1.02_x02           72            53        be          5  \n",
       "pcc_eng_sample-1_1.03_x04           47            39        be          3  \n",
       "pcc_eng_sample-1_1.04_x07           45            30       the          4  \n",
       "pcc_eng_sample-1_1.05_x08           42            30      have          3  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def describe_counts(df, prefix: str='s'):\n",
    "    \n",
    "    doc_dict = {}\n",
    "    counts = df.loc[:, df.columns.str.endswith('count')]\n",
    "    \n",
    "    #> replaces code below for renaming\n",
    "    counts.columns = counts.columns.str.replace('count','').str.strip('_')\n",
    "    \n",
    "    # first descriptor is \"count\" ~ do not need, so drop it here\n",
    "    counts_desc = counts.describe().iloc[1:, :]\n",
    "    # add median and sum rows, but \"assign\" as columns\n",
    "    t_counts_desc = counts_desc.transpose().assign(\n",
    "        #! turns out median is identical with `50%` value already in `counts_desc`\n",
    "        #   and `wrd_total` is redundant with lmm_count but leaving that\n",
    "        # median=counts.median(),\n",
    "        total=counts.sum())\n",
    "\n",
    "    #// # rename data type labels: e.g. wrd_count -> wrd\n",
    "    #// #// t_counts_desc.index = t_counts_desc.index.str.replace('count', '').str.replace('_','',1)\n",
    "    #// t_counts_desc.index = t_counts_desc.index.str.split('_').str.get(0)\n",
    "\n",
    "    # for each row of combined descriptive stats automated df:\n",
    "    #   1. pull out row as its *own* dataframe\n",
    "    #   2. rename cols to indicate row/data (i.e. 'wrd_' or 'chr_')\n",
    "    for row_ix in t_counts_desc.index:\n",
    "        row_df = t_counts_desc.loc[[row_ix], :]\n",
    "        # print('generalized `describe` metrics:',row_df.columns.to_list(),sep='\\n')\n",
    "        row_df.columns = prefix+row_ix+'_'+row_df.columns\n",
    "        # print('--become-->')\n",
    "        # print('individualized `describe` metrics:', row_df.columns.to_list(), sep='\\n')\n",
    "        row = row_df.iloc[0, :]\n",
    "        row_dict = row.to_dict()\n",
    "        doc_dict.update(row_dict)\n",
    "    # pprint(doc_dict)\n",
    "    return doc_dict\n",
    "\n",
    "#### Loop through by-sentence dataframe\n",
    "\n",
    "d_dicts = []\n",
    "prefix = 'S'\n",
    "# TODO: make this a method/function\n",
    "for doc, gdf in sdf.groupby('did'):\n",
    "    # print(doc)\n",
    "    doc_dict = describe_counts(gdf,prefix)\n",
    "    doc_dict = {f'D_{k}':v for k,v in doc_dict.items()}\n",
    "    # (moved to independent function)\n",
    "    # doc_dict = {}\n",
    "    # s_counts = gdf.loc[:, gdf.columns.str.endswith('count')]\n",
    "    \n",
    "    # # first descriptor is \"count\" ~ do not need, so drop it here\n",
    "    # counts_desc = s_counts.describe().iloc[1:, :]\n",
    "    \n",
    "    # # add median and sum rows, but \"assign\" as columns\n",
    "    # t_counts_desc = counts_desc.transpose().assign(\n",
    "    #     median=s_counts.median(),\n",
    "    #     sum=s_counts.sum()\n",
    "    # )\n",
    "\n",
    "    # # rename data type labels: e.g. s_wrd_count -> wrd\n",
    "    # #// t_counts_desc.index = t_counts_desc.index.str.replace('count', '').str.replace('_','',1)\n",
    "    # t_counts_desc.index = t_counts_desc.index.str.split('_').str.get(1)\n",
    "\n",
    "    # # for each row of combined descriptive stats automated df\n",
    "    # #   pull out row as its *own* df\n",
    "    # #   rename cols to indicate row/data (i.e. wrd vs. chr)\n",
    "    # for row_ix in t_counts_desc.index:\n",
    "    #     row_df = t_counts_desc.loc[[row_ix], :]\n",
    "    #     print(row_df.columns.to_list())\n",
    "    #     row_df.columns = 's'+row_ix+'_'+row_df.columns\n",
    "    #     print('--become-->')\n",
    "    #     print(row_df.columns.to_list())\n",
    "    #     row = row_df.iloc[0, :]\n",
    "    #     row_dict = row.to_dict()\n",
    "    #     doc_dict.update(row_dict)\n",
    "    # pprint(doc_dict)\n",
    "\n",
    "    # (previous method of getting values individually)\n",
    "    #// s_chr = gdf.s_chr_count\n",
    "    #// s_chr_des = s_chr.describe()\n",
    "    #// d_chr = s_chr.sum()\n",
    "    #// d_mn_s_chr = s_chr.mean()\n",
    "    #// d_md_s_chr = s_chr.median()\n",
    "    #// d_least_char = s_chr.min()\n",
    "    #// d_most_char = s_chr.max()\n",
    "    #// s_wrd = gdf.s_wrd_count\n",
    "    #// s_wrd.describe()\n",
    "    #// d_wrd = s_wrd.sum()\n",
    "    #// d_mn_s_wrd = s_wrd.mean()  # * same\n",
    "    #// d_md_s_wrd = s_wrd.median()\n",
    "    #// d_least_words = s_wrd.min()\n",
    "    #// d_most_words = s_wrd.max()\n",
    "\n",
    "    #TODO: 👉 use `s_wlen_list` col to calculate mean doc wlen (or not??)\n",
    "    #NOTE: decided best to calculate average word length from raw word lengths for entire doc, \n",
    "    # rather than the mean of sentence specific mean word length. \n",
    "    #// d_mn_s_mn_wlen = gdf.s_wlen_mean.mean()\n",
    "    #// d_mn_s_md_wlen = gdf.s_wlen_median.mean()\n",
    "    #// d_md_s_md_wlen = gdf.s_wlen_median.median()\n",
    "    \n",
    "    #! mode is problematic for dataframes: returns list ~OR~ number\n",
    "    #// d_mo_s_md_wlen = gdf.s_wlen_median.mode()\n",
    "    doc_lemmas = pd.Series(lm for lm_list in gdf.lmm_list for lm in lm_list)\n",
    "    doc_wlens = pd.Series(wl for wl_list in gdf.wlen_list for wl in wl_list)\n",
    "    doc_add = {\n",
    "        #> discarded values/approaches\n",
    "        # (determined better to calculate directly vs. `mean(mean(SVAL))`)\n",
    "        #// 'd_mean_scomplexity': d_mn_s_mn_wlen,  # doc mean of sent mean word length\n",
    "        \n",
    "        #! causes issues because not always a single value\n",
    "        # // 'd_mo_s_md_wlen': d_mo_s_md_wlen,  # doc mode of sent median word length\n",
    "        \n",
    "        # (previous approach values. Replaced with `describe()` output)\n",
    "        #// total characters in doc (~ doc length in characters)\n",
    "        #// 'd_chr_count': d_chr,\n",
    "        #// 'd_slenc_mean': d_mn_s_chr,  # mean sent length in characters\n",
    "        #// 'd_slenc_median': d_md_s_chr,  # median sent length in characters\n",
    "        #// total words in doc (~ doc length in words)\n",
    "        #// 'd_wrd_count': d_wrd,\n",
    "        #// 'd_slenw_mean': d_mn_s_wrd,  # mean sent length in words\n",
    "        #// 'd_slenw_median': d_md_s_wrd,  # median sent length in words\n",
    "        #// 'd_min_s_chr': d_least_char,\n",
    "        #// 'd_max_s_chr': d_most_char,\n",
    "        #// 'd_min_s_wrd': d_least_words,\n",
    "        #// 'd_max_s_wrd': d_most_words,\n",
    "\n",
    "        # document id\n",
    "        'D_id': doc,  \n",
    "              \n",
    "        # total sentences in doc (~ sentences/per doc)\n",
    "        # (synonymous with the `count` descriptors dropped above)\n",
    "        'D_snt_count': len(gdf),\n",
    "\n",
    "        # total char in doc / total words in doc\n",
    "        'D_wlen_mean': doc_dict[f'D_{prefix}chr_total']/doc_dict[f'D_{prefix}wrd_total'],\n",
    "        # NOTE: this 👆 could also be done by getting the mean of all \n",
    "        #   the wlen elements for each value/cell of `s_wlen_list` col, \n",
    "        #   but that is unnecessary: this returns identical result\n",
    "\n",
    "        #? How do these values differ from existing values output by `describe_sent_counts`?\n",
    "        #?// Does median word length for all words in doc require access to `s_wlen_list`?\n",
    "        #^ think I had determined median word length was unneccesary\n",
    "        #// 'd_mn_s_md_wlen': d_mn_s_md_wlen,  # doc mean of sent median word length\n",
    "        #//'d_md_s_md_wlen': d_md_s_md_wlen,  # doc median of sent median word length\n",
    "        'D_lemmas': doc_lemmas, \n",
    "        'D_wlens': doc_wlens\n",
    "    }\n",
    "    doc_dict.update(doc_add)\n",
    "    \n",
    "    doc_lemmas_desc = doc_lemmas.describe()\n",
    "    doc_lemmas_desc.index = 'D_lmm_'+doc_lemmas_desc.index\n",
    "    doc_dict.update(doc_lemmas_desc.to_dict())\n",
    "    d_dicts.append(doc_dict)\n",
    "d_stats = pd.DataFrame(d_dicts).convert_dtypes()\n",
    "d_stats = d_stats.assign(D_id=d_stats.D_id.astype('string')).set_index('D_id')\n",
    "# print('\\n# dtypes as created:')\n",
    "# print_col_info(d_stats)\n",
    "d_stats.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🚩 Apparently converting dtypes makes them *larger* slightly... this seems to coincide with the strange capitalization difference... 🤔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('# dtypes after auto dtype conversion:')\n",
    "# print_col_info(d_stats.convert_dtypes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These metrics are redundant: \n",
      "D_Swrd_50%\n",
      "D_Swrd_median\n",
      "D_Swrd_total\n",
      "D_Schr_50%\n",
      "D_Schr_median\n",
      "D_lmm_count\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>D_id</th>\n",
       "      <th>pcc_eng_sample-1_1.01_x01</th>\n",
       "      <th>pcc_eng_sample-1_1.02_x02</th>\n",
       "      <th>pcc_eng_sample-1_1.03_x04</th>\n",
       "      <th>pcc_eng_sample-1_1.04_x07</th>\n",
       "      <th>pcc_eng_sample-1_1.05_x08</th>\n",
       "      <th>pcc_eng_sample-1_1.06_x09</th>\n",
       "      <th>pcc_eng_sample-1_1.07_x11</th>\n",
       "      <th>pcc_eng_sample-1_1.08_x12</th>\n",
       "      <th>pcc_eng_sample-1_1.09_x13</th>\n",
       "      <th>pcc_eng_sample-1_1.10_x16</th>\n",
       "      <th>pcc_eng_sample-1_1.11_x18</th>\n",
       "      <th>pcc_eng_sample-1_1.12_x19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D_Swrd_50%</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_Swrd_median</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_Schr_50%</th>\n",
       "      <td>31.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>28.5</td>\n",
       "      <td>47.5</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_Schr_median</th>\n",
       "      <td>31.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>28.5</td>\n",
       "      <td>47.5</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_Swrd_total</th>\n",
       "      <td>87</td>\n",
       "      <td>72</td>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>467</td>\n",
       "      <td>385</td>\n",
       "      <td>667</td>\n",
       "      <td>131</td>\n",
       "      <td>210</td>\n",
       "      <td>83</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_lmm_count</th>\n",
       "      <td>87</td>\n",
       "      <td>72</td>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>467</td>\n",
       "      <td>385</td>\n",
       "      <td>667</td>\n",
       "      <td>131</td>\n",
       "      <td>210</td>\n",
       "      <td>83</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "D_id          pcc_eng_sample-1_1.01_x01 pcc_eng_sample-1_1.02_x02  \\\n",
       "D_Swrd_50%                          9.0                       9.5   \n",
       "D_Swrd_median                       9.0                       9.5   \n",
       "D_Schr_50%                         31.0                      37.5   \n",
       "D_Schr_median                      31.0                      37.5   \n",
       "D_Swrd_total                         87                        72   \n",
       "D_lmm_count                          87                        72   \n",
       "\n",
       "D_id          pcc_eng_sample-1_1.03_x04 pcc_eng_sample-1_1.04_x07  \\\n",
       "D_Swrd_50%                          7.0                      10.5   \n",
       "D_Swrd_median                       7.0                      10.5   \n",
       "D_Schr_50%                         28.5                      47.5   \n",
       "D_Schr_median                      28.5                      47.5   \n",
       "D_Swrd_total                         47                        45   \n",
       "D_lmm_count                          47                        45   \n",
       "\n",
       "D_id          pcc_eng_sample-1_1.05_x08 pcc_eng_sample-1_1.06_x09  \\\n",
       "D_Swrd_50%                         18.0                      17.5   \n",
       "D_Swrd_median                      18.0                      17.5   \n",
       "D_Schr_50%                         77.0                      77.5   \n",
       "D_Schr_median                      77.0                      77.5   \n",
       "D_Swrd_total                         42                       467   \n",
       "D_lmm_count                          42                       467   \n",
       "\n",
       "D_id          pcc_eng_sample-1_1.07_x11 pcc_eng_sample-1_1.08_x12  \\\n",
       "D_Swrd_50%                          9.0                      18.0   \n",
       "D_Swrd_median                       9.0                      18.0   \n",
       "D_Schr_50%                         27.0                      83.0   \n",
       "D_Schr_median                      27.0                      83.0   \n",
       "D_Swrd_total                        385                       667   \n",
       "D_lmm_count                         385                       667   \n",
       "\n",
       "D_id          pcc_eng_sample-1_1.09_x13 pcc_eng_sample-1_1.10_x16  \\\n",
       "D_Swrd_50%                         17.0                      12.5   \n",
       "D_Swrd_median                      17.0                      12.5   \n",
       "D_Schr_50%                        106.0                      67.0   \n",
       "D_Schr_median                     106.0                      67.0   \n",
       "D_Swrd_total                        131                       210   \n",
       "D_lmm_count                         131                       210   \n",
       "\n",
       "D_id          pcc_eng_sample-1_1.11_x18 pcc_eng_sample-1_1.12_x19  \n",
       "D_Swrd_50%                          4.0                      19.0  \n",
       "D_Swrd_median                       4.0                      19.0  \n",
       "D_Schr_50%                         15.0                      90.0  \n",
       "D_Schr_median                      15.0                      90.0  \n",
       "D_Swrd_total                         83                       137  \n",
       "D_lmm_count                          83                       137  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashable_stats = d_stats.loc[:, d_stats.dtypes != 'object']\n",
    "trans_d_df = hashable_stats.transpose()\n",
    "same_vals = trans_d_df.duplicated(keep=False)\n",
    "equivalent_metrics = trans_d_df.loc[same_vals, :]\n",
    "if equivalent_metrics.empty: \n",
    "    print('No metrics are identical/redundant.')\n",
    "else: \n",
    "    print('These metrics are redundant:', ''.join('\\n'+i for i in equivalent_metrics.index))\n",
    "equivalent_metrics.sort_values(equivalent_metrics.columns[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👆 apparently `describe()`'s `50%` output is the same thing as `median()` (which makes sense, but I was not aware it wasn't a different metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No other metrics are similar enough to collapse entirely.\n"
     ]
    }
   ],
   "source": [
    "round_transdf = hashable_stats.transpose().round()\n",
    "almost_same = round_transdf.duplicated(keep=False)\n",
    "similar_metrics = round_transdf.loc[almost_same, :]\n",
    "similar_metrics = similar_metrics.loc[~similar_metrics.index.isin(\n",
    "    equivalent_metrics.index), :]\n",
    "if similar_metrics.empty:\n",
    "    print('No other metrics are similar enough to collapse entirely.')\n",
    "else:\n",
    "    print('These metrics could be collapsed:')\n",
    "    similar_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# by_d_df = d_stats.loc[:,\n",
    "#     # columns to perpetuate\n",
    "#     d_stats.columns.str.startswith('doc')\n",
    "# ].round(3)\n",
    "# by_d_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing if it comes out the same to average on top of averages or just do the calculation directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any(by_d_df.d_mean_s_avg_word_len != by_d_df.d_char_per_word)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dev-sanpi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a82d64a7e868996b1805260a9c82ff1f9f38ed6473139e2deee21ec8e5331945"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
