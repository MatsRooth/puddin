{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirm Text/Document ID Coverage\n",
    "All (Pcc) texts in the original pile files as saved in `pile_tables/raw/` should show up in either the exclusions file for that data group (i.e. as row in the exclusions dataframe) or the final conllu directory (i.e. as a document ~ `new_doc` comment in one of the conllu files there). \n",
    "\n",
    "This notebook works through collecting the IDs found in each of these 3 places and comparing the resulting objects to confirm nothing has been lost.\n",
    "\n",
    "_One possible concern however, is that the exclusions files may be inaccurate. That is, there are documents that were erroneously marked as `fail`s and skipped during parsing, but then successfully completed in a following reparse. So really, it's just the comparison of the raw dataframes and the conllu files that matter, and any that are missing should be in the exclusions dataframe. After this comparison is drawn, documents/texts added to the exclusions in error (i.e. IDs that actually do have parsed sentences in a conllu file) should be removed from the exclusions dataframe_\n",
    "\n",
    "If there are raw text IDs not found in the conllu files or the exclusions, the final (top level `pile_tables/`) and temporary (`pile_tables/tmp/`) should be searched and/or the dataframes in `slices/[data group]/tmp/` should be compared with \"final\" slices in `slices/[data group]/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "#!/home/arh234/.conda/envs/dev-sanpi/bin/python\n",
    "\n",
    "import pandas as pd\n",
    "import pyconll\n",
    "\n",
    "from pathlib import Path\n",
    "# from datetime import datetime\n",
    "# tstamp = datetime.fromtimestamp\n",
    "DATA_DIR = Path('/share/compling/data/puddin')\n",
    "DATA_GRP = 'val'\n",
    "DF_NAME = f'pile_{DATA_GRP}_Pile-CC_df.pkl.gz'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load meta info dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record</th>\n",
       "      <th>slice_name</th>\n",
       "      <th>total_texts</th>\n",
       "      <th>first_text_id</th>\n",
       "      <th>last_text_id</th>\n",
       "      <th>tmp_slice_path</th>\n",
       "      <th>final_slice_path</th>\n",
       "      <th>conllu_path</th>\n",
       "      <th>origin_filepath</th>\n",
       "      <th>data_origin_group</th>\n",
       "      <th>...</th>\n",
       "      <th>seconds</th>\n",
       "      <th>kept_df_mtime</th>\n",
       "      <th>excl_df_mtime</th>\n",
       "      <th>slice_df_mtime</th>\n",
       "      <th>conllu_mtime</th>\n",
       "      <th>kept_df_gzMB</th>\n",
       "      <th>excl_df_gzMB</th>\n",
       "      <th>slice_df_gzMB</th>\n",
       "      <th>conllu_MB</th>\n",
       "      <th>end_timedelta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29-001-0013</td>\n",
       "      <td>Pcc29_1</td>\n",
       "      <td>9999</td>\n",
       "      <td>pcc_eng_29_001.0001_x0000001</td>\n",
       "      <td>pcc_eng_29_001.9999_x0016002</td>\n",
       "      <td>pile_tables/slices/Pcc29/tmp/pile_29-001_Pile-...</td>\n",
       "      <td>pile_tables/slices/Pcc29/pile_29-001_Pile-CC_d...</td>\n",
       "      <td>Pcc29.conll/pcc_eng_29-001.conllu</td>\n",
       "      <td>/share/compling/data/pile/train/29.jsonl</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>3094</td>\n",
       "      <td>2022-03-27 02:12:00</td>\n",
       "      <td>2022-04-30 03:31:00</td>\n",
       "      <td>2022-04-12 21:17:00</td>\n",
       "      <td>2022-04-12 22:13:00</td>\n",
       "      <td>1015.2</td>\n",
       "      <td>0.09</td>\n",
       "      <td>9.33</td>\n",
       "      <td>376.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28-001-0014</td>\n",
       "      <td>Pcc28_1</td>\n",
       "      <td>9999</td>\n",
       "      <td>pcc_eng_28_001.0001_x0000001</td>\n",
       "      <td>pcc_eng_28_001.9999_x0016230</td>\n",
       "      <td>pile_tables/slices/Pcc28/tmp/pile_28-001_Pile-...</td>\n",
       "      <td>pile_tables/slices/Pcc28/pile_28-001_Pile-CC_d...</td>\n",
       "      <td>Pcc28.conll/pcc_eng_28-001.conllu</td>\n",
       "      <td>/share/compling/data/pile/train/28.jsonl</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>2505</td>\n",
       "      <td>2022-04-02 06:13:00</td>\n",
       "      <td>2022-06-28 15:20:00</td>\n",
       "      <td>2022-04-12 21:27:00</td>\n",
       "      <td>2022-04-12 22:13:00</td>\n",
       "      <td>1014.1</td>\n",
       "      <td>1750.58</td>\n",
       "      <td>9.36</td>\n",
       "      <td>377.91</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28-002-0016</td>\n",
       "      <td>Pcc28_2</td>\n",
       "      <td>9999</td>\n",
       "      <td>pcc_eng_28_002.0001_x0016232</td>\n",
       "      <td>pcc_eng_28_002.9999_x0032272</td>\n",
       "      <td>pile_tables/slices/Pcc28/tmp/pile_28-002_Pile-...</td>\n",
       "      <td>pile_tables/slices/Pcc28/pile_28-002_Pile-CC_d...</td>\n",
       "      <td>Pcc28.conll/pcc_eng_28-002.conllu</td>\n",
       "      <td>/share/compling/data/pile/train/28.jsonl</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>2514</td>\n",
       "      <td>2022-04-02 06:13:00</td>\n",
       "      <td>2022-06-28 15:20:00</td>\n",
       "      <td>2022-04-12 21:27:00</td>\n",
       "      <td>2022-04-12 22:55:00</td>\n",
       "      <td>1014.1</td>\n",
       "      <td>1750.58</td>\n",
       "      <td>9.29</td>\n",
       "      <td>375.33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29-002-0017</td>\n",
       "      <td>Pcc29_2</td>\n",
       "      <td>9999</td>\n",
       "      <td>pcc_eng_29_002.0001_x0016004</td>\n",
       "      <td>pcc_eng_29_002.9999_x0032274</td>\n",
       "      <td>pile_tables/slices/Pcc29/tmp/pile_29-002_Pile-...</td>\n",
       "      <td>pile_tables/slices/Pcc29/pile_29-002_Pile-CC_d...</td>\n",
       "      <td>Pcc29.conll/pcc_eng_29-002.conllu</td>\n",
       "      <td>/share/compling/data/pile/train/29.jsonl</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>3188</td>\n",
       "      <td>2022-03-27 02:12:00</td>\n",
       "      <td>2022-04-30 03:31:00</td>\n",
       "      <td>2022-04-12 21:17:00</td>\n",
       "      <td>2022-04-12 23:06:00</td>\n",
       "      <td>1015.2</td>\n",
       "      <td>0.09</td>\n",
       "      <td>9.64</td>\n",
       "      <td>393.87</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28-003-0019</td>\n",
       "      <td>Pcc28_3</td>\n",
       "      <td>9999</td>\n",
       "      <td>pcc_eng_28_003.0001_x0032273</td>\n",
       "      <td>pcc_eng_28_003.9999_x0048538</td>\n",
       "      <td>pile_tables/slices/Pcc28/tmp/pile_28-003_Pile-...</td>\n",
       "      <td>pile_tables/slices/Pcc28/pile_28-003_Pile-CC_d...</td>\n",
       "      <td>Pcc28.conll/pcc_eng_28-003.conllu</td>\n",
       "      <td>/share/compling/data/pile/train/28.jsonl</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>2512</td>\n",
       "      <td>2022-04-02 06:13:00</td>\n",
       "      <td>2022-06-28 15:20:00</td>\n",
       "      <td>2022-04-12 21:27:00</td>\n",
       "      <td>2022-04-12 23:37:00</td>\n",
       "      <td>1014.1</td>\n",
       "      <td>1750.58</td>\n",
       "      <td>9.42</td>\n",
       "      <td>381.21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        record slice_name  total_texts                 first_text_id  \\\n",
       "0  29-001-0013    Pcc29_1         9999  pcc_eng_29_001.0001_x0000001   \n",
       "1  28-001-0014    Pcc28_1         9999  pcc_eng_28_001.0001_x0000001   \n",
       "2  28-002-0016    Pcc28_2         9999  pcc_eng_28_002.0001_x0016232   \n",
       "3  29-002-0017    Pcc29_2         9999  pcc_eng_29_002.0001_x0016004   \n",
       "4  28-003-0019    Pcc28_3         9999  pcc_eng_28_003.0001_x0032273   \n",
       "\n",
       "                   last_text_id  \\\n",
       "0  pcc_eng_29_001.9999_x0016002   \n",
       "1  pcc_eng_28_001.9999_x0016230   \n",
       "2  pcc_eng_28_002.9999_x0032272   \n",
       "3  pcc_eng_29_002.9999_x0032274   \n",
       "4  pcc_eng_28_003.9999_x0048538   \n",
       "\n",
       "                                      tmp_slice_path  \\\n",
       "0  pile_tables/slices/Pcc29/tmp/pile_29-001_Pile-...   \n",
       "1  pile_tables/slices/Pcc28/tmp/pile_28-001_Pile-...   \n",
       "2  pile_tables/slices/Pcc28/tmp/pile_28-002_Pile-...   \n",
       "3  pile_tables/slices/Pcc29/tmp/pile_29-002_Pile-...   \n",
       "4  pile_tables/slices/Pcc28/tmp/pile_28-003_Pile-...   \n",
       "\n",
       "                                    final_slice_path  \\\n",
       "0  pile_tables/slices/Pcc29/pile_29-001_Pile-CC_d...   \n",
       "1  pile_tables/slices/Pcc28/pile_28-001_Pile-CC_d...   \n",
       "2  pile_tables/slices/Pcc28/pile_28-002_Pile-CC_d...   \n",
       "3  pile_tables/slices/Pcc29/pile_29-002_Pile-CC_d...   \n",
       "4  pile_tables/slices/Pcc28/pile_28-003_Pile-CC_d...   \n",
       "\n",
       "                         conllu_path  \\\n",
       "0  Pcc29.conll/pcc_eng_29-001.conllu   \n",
       "1  Pcc28.conll/pcc_eng_28-001.conllu   \n",
       "2  Pcc28.conll/pcc_eng_28-002.conllu   \n",
       "3  Pcc29.conll/pcc_eng_29-002.conllu   \n",
       "4  Pcc28.conll/pcc_eng_28-003.conllu   \n",
       "\n",
       "                            origin_filepath data_origin_group  ... seconds  \\\n",
       "0  /share/compling/data/pile/train/29.jsonl                29  ...    3094   \n",
       "1  /share/compling/data/pile/train/28.jsonl                28  ...    2505   \n",
       "2  /share/compling/data/pile/train/28.jsonl                28  ...    2514   \n",
       "3  /share/compling/data/pile/train/29.jsonl                29  ...    3188   \n",
       "4  /share/compling/data/pile/train/28.jsonl                28  ...    2512   \n",
       "\n",
       "         kept_df_mtime        excl_df_mtime       slice_df_mtime  \\\n",
       "0  2022-03-27 02:12:00  2022-04-30 03:31:00  2022-04-12 21:17:00   \n",
       "1  2022-04-02 06:13:00  2022-06-28 15:20:00  2022-04-12 21:27:00   \n",
       "2  2022-04-02 06:13:00  2022-06-28 15:20:00  2022-04-12 21:27:00   \n",
       "3  2022-03-27 02:12:00  2022-04-30 03:31:00  2022-04-12 21:17:00   \n",
       "4  2022-04-02 06:13:00  2022-06-28 15:20:00  2022-04-12 21:27:00   \n",
       "\n",
       "          conllu_mtime kept_df_gzMB  excl_df_gzMB  slice_df_gzMB conllu_MB  \\\n",
       "0  2022-04-12 22:13:00       1015.2          0.09           9.33    376.85   \n",
       "1  2022-04-12 22:13:00       1014.1       1750.58           9.36    377.91   \n",
       "2  2022-04-12 22:55:00       1014.1       1750.58           9.29    375.33   \n",
       "3  2022-04-12 23:06:00       1015.2          0.09           9.64    393.87   \n",
       "4  2022-04-12 23:37:00       1014.1       1750.58           9.42    381.21   \n",
       "\n",
       "   end_timedelta  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.read_csv(DATA_DIR.joinpath('completed-puddin_meta-index.csv'))\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each row (i.e. slice) compare the text ids found in the files at the following paths: raw, final, conllu. Make sure any missing from conllu are in exclusions dataframe.\n",
    "\n",
    "_Should probably group by exclusions path/data group/original data source column_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newdocs_iter(conll_dir):\n",
    "    for f in conll_dir.glob('*.conllu'):\n",
    "        for s in pyconll.iter_from_file(str(f)):\n",
    "            try:\n",
    "                doc_id = s.meta_value('newdoc id')\n",
    "            except KeyError:\n",
    "                continue\n",
    "            recons_raw_id = '_'.join([x.replace('x', '')\n",
    "                                     for x in doc_id.split('_')[0:5:2]])\n",
    "            yield recons_raw_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "findfs = []\n",
    "rawdfs = []\n",
    "problems = []\n",
    "for grp, mdf in meta.groupby('exclusions_path'):\n",
    "    excl_path = DATA_DIR.joinpath(grp)\n",
    "    # print(excl_path)\n",
    "    #sanity checks\n",
    "    if len(mdf.final_df_path.unique()) != 1: \n",
    "        print('WARNING! different paths showing for final df')\n",
    "    if len(mdf.origin_filepath.unique()) != 1: \n",
    "        print('WARNING! different paths showing for source file')\n",
    "    findf_path = DATA_DIR.joinpath(mdf.final_df_path.iloc[0])\n",
    "    # print(findf_path)\n",
    "    rawdf_path = DATA_DIR.joinpath(f'pile_tables/raw/{findf_path.name}')\n",
    "    # print(rawdf_path)\n",
    "    conll_dir = DATA_DIR.joinpath(Path(mdf.conllu_path.iloc[0]).parent)\n",
    "    # print(conllu_dir)\n",
    "    # print('...........\\n')\n",
    "\n",
    "    #* now check text ids for each\n",
    "    rawdf = pd.read_pickle(rawdf_path)\n",
    "    findf = pd.read_pickle(findf_path)\n",
    "    excldf = pd.read_pickle(excl_path)\n",
    "    conllu_ids = set(newdocs_iter(conll_dir))\n",
    "\n",
    "    findf = findf.assign(late_excl = ~findf.text_id.isin(conllu_ids))\n",
    "    rawdf = rawdf.assign(init_excl = ~rawdf.text_id.isin(findf.text_id))\n",
    "    all_excl_ids = findf.text_id.loc[findf.late_excl] + rawdf.text_id.loc[rawdf.init_excl]\n",
    "    unaccounted = [i for i in all_excl_ids not in excldf.text_id]\n",
    "    print(unaccounted)\n",
    "    problems.append(unaccounted)\n",
    "\n",
    "##? turn this into a dataframe with raw text id as index and columns as booleans for e.g. 'in final df', 'in exclusions', 'in conllu parse', etc?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get the original text IDs from the raw dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ex = pd.read_pickle(DATA_DIR.joinpath(\n",
    "    f'pile_tables/raw/{DF_NAME}'))\n",
    "# raw_ex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get the text IDs from the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_ex = pd.read_pickle(DATA_DIR.joinpath(f'pile_tables/{DF_NAME}'))\n",
    "fin_ex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_excl = raw_ex.loc[~ raw_ex.text_id.isin(fin_ex.text_id),'text_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get the document (text) IDs from the finalized conllu files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_conllu = [i for i in fin_ex.text_id if i not in doc_ids]\n",
    "not_in_conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_ex.text_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dev-sanpi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2be2110b1b66d6fb5ee0f81eed9f7e144276a208b014862682c0da85a50192a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
